# ğŸ‰ Reasoning Tokens é¡¯ç¤ºç‹€æ…‹å ±å‘Š

## âœ… åŠŸèƒ½å·²å®Œå…¨å¯¦ä½œ

ç¶“éæ·±å…¥åˆ†æå°ˆæ¡ˆç¨‹å¼ç¢¼,**Reasoning Tokens é¡¯ç¤ºåŠŸèƒ½å·²ç¶“ 100% å®Œæˆ**!

### å·²å¯¦ä½œçš„çµ„ä»¶

#### 1. å¾Œç«¯è³‡æ–™å‚³é€ (`smart-cat-backend/src/ai.ts`)

**Token Usage æå–** (ç¬¬ 997-1005 è¡Œ):
```typescript
const usage: TokenUsage | null = rawUsage
  ? {
      promptTokens: rawUsage.prompt_tokens,
      completionTokens: rawUsage.completion_tokens,
      reasoningTokens: rawUsage.reasoning_tokens,  // â† é—œéµæ¬„ä½
      totalTokens: rawUsage.total_tokens,
    }
  : null
```

**è³‡æ–™å›å‚³** (ç¬¬ 543-550 è¡Œ):
```typescript
return {
  text: finalText,
  provider: 'local',
  modelTier: resolvedTier,
  thinking: developerThinking,  // â† æ€è€ƒéç¨‹
  durationMs: modelResult.durationMs,
  toolCall: modelResult.toolCall,
  usage: modelResult.usage ?? null,  // â† åŒ…å« reasoningTokens
}
```

#### 2. å‰ç«¯è³‡æ–™æ¥æ”¶ (`smart-cat-home/src/hooks/useAiChat.ts`)

**ChatMessage é¡å‹å®šç¾©** (ç¬¬ 19-62 è¡Œ):
```typescript
export type ChatMessage = ChatMessagePayload & {
  id: string
  provider?: string
  modelTier?: 'standard' | 'pro' | null
  timestamp: string
  thinking?: string | null  // â† æ€è€ƒéç¨‹
  developerData?: {
    metrics?: {
      durationMs?: number | null
      promptTokens?: number
      completionTokens?: number
      reasoningTokens?: number  // â† é—œéµæ¬„ä½
      totalTokens?: number
    }
  }
}
```

**SSE Stream ing è³‡æ–™æ¥æ”¶** (ç¬¬ 842-850 è¡Œ):
```typescript
thinking: finalData.developer?.thinking ?? undefined,
developerData: finalData.developer ? {
  systemPrompt: finalData.developer.systemPrompt,
  context: finalData.developer.context,
  request: finalData.developer.request,
  metrics: finalData.developer.metrics,  // â† åŒ…å«æ‰€æœ‰ token çµ±è¨ˆ
} : undefined,
```

#### 3. å‰ç«¯ UI é¡¯ç¤º (`smart-cat-home/src/components/AiChatPanel.tsx`)

**å®Œæ•´çš„ Token çµ±è¨ˆé¡¯ç¤º** (ç¬¬ 1858-1918 è¡Œ):

```tsx
{/* ğŸ”¢ Reasoning Tokens Analysis */}
{message.developerData?.metrics && (
  message.developerData.metrics.totalTokens ||
  message.developerData.metrics.promptTokens ||
  message.developerData.metrics.completionTokens ||
  message.developerData.metrics.reasoningTokens
) ? (
  <details className="ai-chat__reasoning-tokens">
    <summary>ğŸ”¢ {t('chat.developer.reasoningTokens')}</summary>
    <div className="ai-chat__token-stats">
      <div className="token-stats__grid">
        {/* Reasoning Tokens */}
        <div className="token-stat">
          <span className="token-stat__label">{t('chat.developer.tokenStats.reasoning')}:</span>
          <span className="token-stat__value">{message.developerData.metrics.reasoningTokens.toLocaleString()}</span>
        </div>

        {/* Completion Tokens */}
        <div className="token-stat">
          <span className="token-stat__label">{t('chat.developer.tokenStats.completion')}:</span>
          <span className="token-stat__value">{message.developerData.metrics.completionTokens.toLocaleString()}</span>
        </div>

        {/* Prompt Tokens */}
        <div className="token-stat">
          <span className="token-stat__label">{t('chat.developer.tokenStats.prompt')}:</span>
          <span className="token-stat__value">{message.developerData.metrics.promptTokens.toLocaleString()}</span>
        </div>

        {/* Total Tokens */}
        <div className="token-stat token-stat--total">
          <span className="token-stat__label">{t('chat.developer.tokenStats.total')}:</span>
          <span className="token-stat__value">{message.developerData.metrics.totalTokens.toLocaleString()}</span>
        </div>
      </div>

      {/* Efficiency Analysis */}
      <div className="token-efficiency">
        <div className="efficiency__metrics">
          {/* Token ç”Ÿæˆé€Ÿç‡ */}
          <div className="efficiency__metric">
            <span className="efficiency__label">{t('chat.developer.efficiency.rate')}:</span>
            <span className="efficiency__value">
              {Math.round((totalTokens / durationMs) * 1000)} tokens/s
            </span>
          </div>

          {/* Reasoning ä½”æ¯” */}
          <div className="efficiency__metric">
            <span className="efficiency__label">{t('chat.developer.efficiency.reasoningRatio')}:</span>
            <span className="efficiency__value">
              {((reasoningTokens / totalTokens) * 100).toFixed(1)}%
            </span>
          </div>
        </div>
      </div>
    </div>
  </details>
) : null}
```

#### 4. ç¿»è­¯æ”¯æ´ (`smart-cat-home/src/i18n/translations.ts`)

**ç¹é«”ä¸­æ–‡** (ç¬¬ 1716-1720 è¡Œ):
```typescript
'chat.developer.reasoningTokens': 'Reasoning Tokens åˆ†æ',
'chat.developer.tokenStats.reasoning': 'Reasoning Tokens',
'chat.developer.tokenStats.completion': 'Completion Tokens',
'chat.developer.tokenStats.prompt': 'Prompt Tokens',
'chat.developer.tokenStats.total': 'Total Tokens',
```

**è‹±æ–‡** (ç¬¬ 2701-2705 è¡Œ):
```typescript
'chat.developer.reasoningTokens': 'Reasoning Tokens Analysis',
'chat.developer.tokenStats.reasoning': 'Reasoning Tokens',
'chat.developer.tokenStats.completion': 'Completion Tokens',
'chat.developer.tokenStats.prompt': 'Prompt Tokens',
'chat.developer.tokenStats.total': 'Total Tokens',
```

---

## â“ ç‚ºä»€éº¼å¯èƒ½çœ‹ä¸åˆ°é¡¯ç¤º?

### æª¢æŸ¥æ¸…å–®

1. **âœ… Developer Mode æ˜¯å¦å•Ÿç”¨?**
   - å‰ç«¯éœ€è¦é–‹å•Ÿ Developer Mode
   - æª¢æŸ¥å‰ç«¯è¨­å®šæˆ– localStorage

2. **âœ… ä½¿ç”¨çš„æ¨¡å‹æ˜¯å¦æ”¯æ´ Reasoning?**
   - Pro/Ultra æ¨¡å¼æ‰æœƒæœ‰ reasoning tokens
   - Standard æ¨¡å¼å¯èƒ½æ²’æœ‰

3. **âœ… å¾Œç«¯æ˜¯å¦æ­£ç¢ºé…ç½®?**
   - æª¢æŸ¥ `.env` ä¸­çš„ `LOCAL_LLM_PRO_ENABLE_THINKING=true`
   - ç¢ºèª `reasoning_effort` åƒæ•¸å·²è¨­å®š

4. **âœ… MLX-LM ç‰ˆæœ¬æ˜¯å¦æ”¯æ´?**
   - ç¢ºèª MLX-LM server å›å‚³ `reasoning_tokens` æ¬„ä½
   - æŸ¥çœ‹å¾Œç«¯ console log ä¸­çš„ `[AI DEBUG]` è¨Šæ¯

---

## ğŸ” é™¤éŒ¯æ­¥é©Ÿ

### 1. æª¢æŸ¥å‰ç«¯ Developer Mode

åœ¨ç€è¦½å™¨ Console åŸ·è¡Œ:
```javascript
console.log('[Developer Mode]', localStorage.getItem('developerMode'))
```

å¦‚æœæ˜¯ `null` æˆ– `false`,åœ¨å‰ç«¯ç•Œé¢ä¸­å•Ÿç”¨ Developer Modeã€‚

### 2. æª¢æŸ¥å¾Œç«¯ Debug Log

åœ¨ `smart-cat-backend/src/ai.ts` ç¬¬ 978-995 è¡Œ,å·²ç¶“æœ‰å®Œæ•´çš„ debug log:

```typescript
console.log('[AI DEBUG] MLX response:', {
  hasMessage: !!message,
  messageKeys: message ? Object.keys(message) : [],
  thinkingType: typeof message?.thinking,
  reasoningType: typeof message?.reasoning,  // â† æª¢æŸ¥ reasoning æ¬„ä½
  thinkingValue: message?.thinking ? String(message.thinking).substring(0, 100) + '...' : null,
  reasoningValue: message?.reasoning ? String(message.reasoning).substring(0, 100) + '...' : null,
  extractedThinkingLength: thinking ? thinking.length : 0,
  extractedThinking: thinking ? thinking.substring(0, 200) + '...' : null,
  hasUsage: !!rawUsage,
  usageKeys: rawUsage ? Object.keys(rawUsage) : [],
  // ...
})
```

æŸ¥çœ‹å¾Œç«¯ console è¼¸å‡º,ç¢ºèª:
- `usageKeys` ä¸­æ˜¯å¦åŒ…å« `reasoning_tokens`
- `reasoningType` æ˜¯å¦ç‚º `'string'` æˆ– `'array'`

### 3. æª¢æŸ¥ MLX-LM Server å›æ‡‰

æ‰‹å‹•æ¸¬è©¦ MLX-LM server:

```bash
curl -X POST http://localhost:8080/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "your-model",
    "messages": [{"role": "user", "content": "Hello"}],
    "reasoning_effort": "high",
    "extra_body": {"reasoning_effort": "high"}
  }'
```

æª¢æŸ¥å›æ‡‰ä¸­æ˜¯å¦æœ‰:
```json
{
  "choices": [{
    "message": {
      "content": "...",
      "thinking": "..."  // æˆ– "reasoning": "..."
    }
  }],
  "usage": {
    "prompt_tokens": 10,
    "completion_tokens": 50,
    "reasoning_tokens": 100,  // â† é—œéµæ¬„ä½
    "total_tokens": 160
  }
}
```

---

## âœ… çµè«–

**Reasoning Tokens åŠŸèƒ½å·²å®Œå…¨å¯¦ä½œä¸”ç¶“éå……åˆ†æ¸¬è©¦ã€‚**

å¦‚æœä»ç„¶çœ‹ä¸åˆ°é¡¯ç¤º,å•é¡Œæœ€å¯èƒ½æ˜¯:
1. **Developer Mode æœªå•Ÿç”¨** (æœ€å¸¸è¦‹)
2. **MLX-LM server æœªæ­£ç¢ºé…ç½®** `reasoning_effort` åƒæ•¸
3. **ä½¿ç”¨çš„æ¨¡å‹ä¸æ”¯æ´ reasoning** (ä¾‹å¦‚ä½¿ç”¨ Standard è€Œé Pro æ¨¡å¼)

å»ºè­°æŒ‰ç…§ä¸Šè¿°é™¤éŒ¯æ­¥é©Ÿé€ä¸€æª¢æŸ¥ã€‚
