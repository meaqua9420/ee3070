/**
 * enhancedVision.ts
 *
 * Enhanced Vision Analysis - Beyond Cats
 *
 * åŠŸèƒ½æ‰©å±•ï¼š
 * - ä¸é™äºçŒ«å’Œå®¶åº­ç¯å¢ƒ
 * - å…¨é¢å®‰å…¨åˆ†æï¼ˆé«˜é£é™©è¡Œä¸ºã€å±é™©ç‰©å“ã€ç¯å¢ƒéšæ‚£ï¼‰
 * - å®æ—¶è§†é¢‘æµåˆ†æï¼ˆå¯é€‰ï¼‰
 * - ç«‹å³è­¦æŠ¥æœºåˆ¶
 */

import type { VisionRiskAnalysis } from './visionRiskAnalyzer'
import { dispatchAlert } from './alertManager'

export interface EnhancedVisionAnalysis {
  // åŸºç¡€åˆ†æ
  description: string
  objects: string[]
  scene: string

  // å®‰å…¨åˆ†æ
  safetyScore: number // 0-10, 10æœ€å®‰å…¨
  hazards: Hazard[]

  // è¡Œä¸ºåˆ†æ
  detectedBehaviors: string[]
  concerningBehaviors: string[]

  // å»ºè®®
  recommendations: string[]
  urgentActions: string[]
}

export interface Hazard {
  type: 'physical' | 'chemical' | 'behavioral' | 'environmental'
  severity: 'low' | 'medium' | 'high' | 'critical'
  description: string
  location?: string
  recommendation: string
}

/**
 * å¢å¼ºçš„è§†è§‰åˆ†æSystem Prompt
 */
export function buildEnhancedVisionPrompt(language: 'zh' | 'en'): string {
  if (language === 'zh') {
    return `ä½ æ˜¯ä¸“ä¸šçš„è§†è§‰å®‰å…¨åˆ†æAIã€‚åˆ†æå›¾ç‰‡æ—¶è¯·å…³æ³¨ï¼š

## ğŸ¯ åˆ†æé‡ç‚¹

### 1. å…¨é¢ç‰©ä½“è¯†åˆ«
- è¯†åˆ«æ‰€æœ‰å¯è§ç‰©ä½“ï¼Œä¸é™äºçŒ«æˆ–å® ç‰©
- æ³¨æ„å±é™©ç‰©å“ï¼šåŒ–å­¦å“ã€å°–é”ç‰©ã€å°ç‰©ä»¶ï¼ˆçª’æ¯é£é™©ï¼‰ã€ç”µçº¿ã€çƒ­æº
- è¯†åˆ«äººå‘˜ã€å® ç‰©ã€å®¶å…·ã€è®¾å¤‡

### 2. å®‰å…¨éšæ‚£æ£€æµ‹ âš ï¸
æ‰«æä»¥ä¸‹é£é™©ï¼š
- **è·Œè½é£é™©**ï¼šå¼€çª—ã€é«˜å¤„ã€ä¸ç¨³å®šç‰©å“
- **ä¸­æ¯’é£é™©**ï¼šæœ‰æ¯’æ¤ç‰©ã€åŒ–å­¦å“ã€è¯ç‰©
- **çª’æ¯é£é™©**ï¼šå°ç‰©ä»¶ã€å¡‘æ–™è¢‹ã€ç»³ç´¢
- **çƒ«ä¼¤é£é™©**ï¼šçƒ­æ°´ã€ç‚‰ç¶ã€åŠ çƒ­è®¾å¤‡
- **ç”µå‡»é£é™©**ï¼šè£¸éœ²ç”µçº¿ã€æ’åº§ã€æŸåç”µå™¨
- **åˆ’ä¼¤é£é™©**ï¼šç»ç’ƒç¢ç‰‡ã€å°–é”ç‰©
- **ç¢°æ’é£é™©**ï¼šä¸ç¨³å®šå®¶å…·ã€æ˜“å€’ç‰©å“

### 3. è¡Œä¸ºåˆ†æ
è¯†åˆ«ç”»é¢ä¸­çš„è¡Œä¸ºï¼š
- æ­£å¸¸è¡Œä¸ºï¼šä¼‘æ¯ã€ç©è€ã€è¿›é£Ÿ
- å…³æ³¨è¡Œä¸ºï¼šæ”€çˆ¬é«˜å¤„ã€é è¿‘å±é™©ç‰©ã€å¼‚å¸¸å§¿åŠ¿
- ç´§æ€¥è¡Œä¸ºï¼šè·Œè½ã€å—å›°ã€æ¥è§¦å±é™©å“

### 4. ç¯å¢ƒè¯„ä¼°
- å…‰çº¿æ¡ä»¶
- é€šé£çŠ¶å†µ
- æ¸…æ´ç¨‹åº¦
- ç©ºé—´å¸ƒå±€åˆç†æ€§

## ğŸ“Š è¾“å‡ºæ ¼å¼ï¼ˆJSONï¼‰

{
  "description": "ç®€æ´æè¿°å›¾ç‰‡å†…å®¹ï¼ˆ2-3å¥ï¼‰",
  "objects": ["ç‰©ä½“1", "ç‰©ä½“2", ...],
  "scene": "åœºæ™¯ç±»å‹ï¼ˆå¦‚ï¼šå®¢å…ã€å¨æˆ¿ã€æˆ·å¤–ç­‰ï¼‰",
  "safetyScore": 8,
  "hazards": [
    {
      "type": "physical",
      "severity": "high",
      "description": "å¼€çª—ä¸”æ— é˜²æŠ¤ç½‘",
      "location": "çª—æˆ·",
      "recommendation": "ç«‹å³å®‰è£…é˜²æŠ¤ç½‘æˆ–å…³é—­çª—æˆ·"
    }
  ],
  "detectedBehaviors": ["çŒ«å’ªåœ¨çª—è¾¹", "æ­£åœ¨è§‚å¯Ÿå¤–é¢"],
  "concerningBehaviors": ["é è¿‘å¼€çª—"],
  "recommendations": [
    "å®‰è£…çª—æˆ·é˜²æŠ¤ç½‘",
    "ç§»é™¤çª—è¾¹ä¸ç¨³å®šç‰©å“"
  ],
  "urgentActions": [
    "ç«‹å³å…³é—­æ— é˜²æŠ¤çš„çª—æˆ·"
  ]
}

## ğŸš¨ ç´§æ€¥æƒ…å†µåˆ¤å®š
å¦‚æœæ£€æµ‹åˆ°critical severity hazardï¼Œå¿…é¡»ï¼š
1. safetyScoreè®¾ä¸ºâ‰¤3
2. urgentActionsä¸­åˆ—å‡ºç«‹å³è¡ŒåŠ¨
3. descriptionä¸­æ˜ç¡®è­¦å‘Š

åªè¾“å‡ºJSONï¼Œä¸è¦é¢å¤–æ–‡å­—ã€‚`
  } else {
    return `You are a professional visual safety analysis AI. When analyzing images, focus on:

## ğŸ¯ Analysis Focus

### 1. Comprehensive Object Recognition
- Identify all visible objects, not limited to cats or pets
- Watch for dangerous items: chemicals, sharp objects, small items (choking hazard), wires, heat sources
- Identify people, pets, furniture, equipment

### 2. Safety Hazard Detection âš ï¸
Scan for these risks:
- **Fall Risk**: Open windows, heights, unstable items
- **Poisoning Risk**: Toxic plants, chemicals, medications
- **Choking Risk**: Small objects, plastic bags, strings
- **Burn Risk**: Hot water, stoves, heating devices
- **Electric Shock Risk**: Exposed wires, outlets, damaged appliances
- **Cut Risk**: Glass shards, sharp objects
- **Impact Risk**: Unstable furniture, tippable items

### 3. Behavior Analysis
Identify behaviors in the scene:
- Normal: resting, playing, eating
- Concerning: climbing high, approaching hazards, unusual posture
- Emergency: falling, trapped, contact with dangerous items

### 4. Environment Assessment
- Lighting conditions
- Ventilation
- Cleanliness
- Space layout rationality

## ğŸ“Š Output Format (JSON)

{
  "description": "Concise image description (2-3 sentences)",
  "objects": ["object1", "object2", ...],
  "scene": "Scene type (e.g., living room, kitchen, outdoor)",
  "safetyScore": 8,
  "hazards": [
    {
      "type": "physical",
      "severity": "high",
      "description": "Open window without safety net",
      "location": "window",
      "recommendation": "Install safety net immediately or close window"
    }
  ],
  "detectedBehaviors": ["cat near window", "observing outside"],
  "concerningBehaviors": ["approaching open window"],
  "recommendations": [
    "Install window safety net",
    "Remove unstable items near window"
  ],
  "urgentActions": [
    "Close unprotected window immediately"
  ]
}

## ğŸš¨ Emergency Determination
If critical severity hazard detected, must:
1. Set safetyScore â‰¤ 3
2. List immediate actions in urgentActions
3. Clear warning in description

Output JSON only, no extra text.`
  }
}

/**
 * åˆ†æå›¾ç‰‡ï¼ˆå¢å¼ºç‰ˆï¼‰
 */
export async function analyzeEnhancedVision(
  imageData: { imageBase64?: string; imageUrl?: string; mimeType?: string },
  visionConfig: any,
  language: 'zh' | 'en' = 'zh'
): Promise<EnhancedVisionAnalysis> {
  const prompt = buildEnhancedVisionPrompt(language)

  // è°ƒç”¨è§†è§‰æ¨¡å‹API
  const payload: any = {
    model: visionConfig.serverModel,
    messages: [
      {
        role: 'user',
        content: [
          { type: 'text', text: prompt },
        ],
      },
    ],
    max_tokens: visionConfig.maxTokens,
    temperature: visionConfig.temperature,
  }

  // æ·»åŠ å›¾ç‰‡
  if (imageData.imageBase64) {
    payload.messages[0].content.push({
      type: 'image_url',
      image_url: {
        url: imageData.imageBase64,
      },
    })
  } else if (imageData.imageUrl) {
    payload.messages[0].content.push({
      type: 'image_url',
      image_url: {
        url: imageData.imageUrl,
      },
    })
  }

  const response = await fetch(visionConfig.serverUrl, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      ...(visionConfig.apiKey ? { Authorization: `Bearer ${visionConfig.apiKey}` } : {}),
    },
    body: JSON.stringify(payload),
    signal: AbortSignal.timeout(visionConfig.timeoutMs || 60000),
  })

  if (!response.ok) {
    throw new Error(`Vision API failed: ${response.status}`)
  }

  const data = (await response.json()) as {
    choices?: Array<{
      message?: {
        content?: string
      }
    }>
  }
  const rawOutput = data.choices?.[0]?.message?.content || ''

  // è§£æJSONè¾“å‡º
  try {
    // æå–JSONï¼ˆå¯èƒ½è¢«markdownä»£ç å—åŒ…è£¹ï¼‰
    let jsonStr = rawOutput
    const match = rawOutput.match(/```json\s*(\{[\s\S]*?\})\s*```/)
    if (match?.[1]) {
      jsonStr = match[1]
    }

    const analysis = JSON.parse(jsonStr) as EnhancedVisionAnalysis

    // è‡ªåŠ¨è§¦å‘ç´§æ€¥è­¦æŠ¥
    if (analysis.urgentActions && analysis.urgentActions.length > 0) {
      await triggerUrgentAlert(analysis, language)
    }

    return analysis
  } catch (e) {
    console.error('[enhanced-vision] Failed to parse JSON:', e)
    // Fallback: åˆ›å»ºåŸºç¡€åˆ†æ
    return {
      description: rawOutput.substring(0, 200),
      objects: [],
      scene: 'unknown',
      safetyScore: 5,
      hazards: [],
      detectedBehaviors: [],
      concerningBehaviors: [],
      recommendations: [],
      urgentActions: [],
    }
  }
}

/**
 * è§¦å‘ç´§æ€¥è­¦æŠ¥
 */
async function triggerUrgentAlert(
  analysis: EnhancedVisionAnalysis,
  language: 'zh' | 'en'
): Promise<void> {
  const criticalHazards = analysis.hazards.filter(h => h.severity === 'critical')
  const highHazards = analysis.hazards.filter(h => h.severity === 'high')

  if (criticalHazards.length === 0 && highHazards.length === 0) {
    return
  }

  const alertMessage = language === 'zh'
    ? `ğŸš¨ è§†è§‰å®‰å…¨è­¦æŠ¥\n\n${analysis.description}\n\nç´§æ€¥è¡ŒåŠ¨ï¼š\n${analysis.urgentActions.map(a => `â€¢ ${a}`).join('\n')}`
    : `ğŸš¨ Visual Safety Alert\n\n${analysis.description}\n\nUrgent Actions:\n${analysis.urgentActions.map(a => `â€¢ ${a}`).join('\n')}`

  await dispatchAlert(
    alertMessage,
    'critical',
    {
      messageKey: 'visionSafetyAlert',
      audioAlert: true,
      showBanner: true,
      autoTask: {
        category: 'safety',
        priority: 'high',
        dueInHours: 0.5, // 30åˆ†é’Ÿå†…å¤„ç†
      },
    }
  )

  console.error('[enhanced-vision] ğŸš¨ URGENT ALERT TRIGGERED:', {
    criticalCount: criticalHazards.length,
    highCount: highHazards.length,
    urgentActions: analysis.urgentActions,
  })
}

/**
 * æ‰¹é‡åˆ†æè§†é¢‘å¸§ï¼ˆå®æ—¶æµåˆ†æï¼‰
 */
export async function analyzeVideoStream(
  frameGenerator: AsyncGenerator<{ imageBase64: string; timestamp: number }>,
  visionConfig: any,
  language: 'zh' | 'en',
  options: {
    analyzeInterval?: number // åˆ†æé—´éš”ï¼ˆæ¯«ç§’ï¼‰ï¼Œé»˜è®¤5000
    onAnalysis?: (analysis: EnhancedVisionAnalysis, frame: number) => void
    onUrgentDetection?: (analysis: EnhancedVisionAnalysis) => void
  } = {}
): Promise<void> {
  const { analyzeInterval = 5000, onAnalysis, onUrgentDetection } = options

  let frameCount = 0
  let lastAnalysisTime = 0

  for await (const frame of frameGenerator) {
    frameCount++
    const now = Date.now()

    // æ§åˆ¶åˆ†æé¢‘ç‡
    if (now - lastAnalysisTime < analyzeInterval) {
      continue
    }

    lastAnalysisTime = now

    try {
      const analysis = await analyzeEnhancedVision(
        { imageBase64: frame.imageBase64, mimeType: 'image/jpeg' },
        visionConfig,
        language
      )

      onAnalysis?.(analysis, frameCount)

      // æ£€æµ‹ç´§æ€¥æƒ…å†µ
      if (analysis.urgentActions.length > 0) {
        onUrgentDetection?.(analysis)
      }
    } catch (error) {
      console.error(`[video-stream] Frame ${frameCount} analysis failed:`, error)
    }
  }
}
